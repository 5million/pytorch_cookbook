{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4edb58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe633a3c170>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "torch.manual_seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524cdbeb",
   "metadata": {},
   "source": [
    "# 1.create a tensor\n",
    "### directly from data\n",
    " * torch.tensor(data, dtype=None, device=None, requires_grad=False, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21c52a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1000,  2.0000],\n",
       "        [-2.0000,  3.0000],\n",
       "        [ 0.5000,  0.2000]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[0.1, 2], [-2, 3], [0.5, 0.2]]\n",
    "torch.tensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e125fb",
   "metadata": {},
   "source": [
    "### from numpy\n",
    " * torch.from_numpy(ndarray, dtype=None, device=None, requires_grad=False, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5d55ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1000,  2.0000],\n",
       "        [-2.0000,  3.0000],\n",
       "        [ 0.5000,  0.2000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "torch.from_numpy(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1154138d",
   "metadata": {},
   "source": [
    "### from another tensor\n",
    "The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden.\n",
    " * torch.ones_like(input, dtype=None, layout=None, device=None, requires_grad=False)\n",
    " * torch.zeros_like(input, dtype=None, layout=None, device=None, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8451d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.from_numpy(data)\n",
    "torch.ones_like(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7458bee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e1a40717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.1416, 3.1416],\n",
       "        [3.1416, 3.1416],\n",
       "        [3.1416, 3.1416]], dtype=torch.float64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full_like(tensor, 3.14159)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b6a3fb",
   "metadata": {},
   "source": [
    "### with random or constant values\n",
    "shape is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of the output tensor\n",
    "* torch.empty(shape)\n",
    "* torch.ones(*size, out=None, dtype=None, layout=torch.strided, device=None, required_grad=False)\n",
    "* torch.zeros(*size, out=None, dtype=None, layout=torch.strided, device=None, required_grad=False)\n",
    "* torch.full(size, fill_value, out=None, dtype=None, layout=torch.strided, device=None, required_grad=False)\n",
    "* torch.arange(start=0, end, step=1, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "* torch.linspace(start, end, steps=100, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "* torch.logspace(start, end, steps=100, base=10.0, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "* torch.eye(n, m=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8842f3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5349, 0.1988, 0.6592],\n",
       "        [0.6569, 0.2328, 0.4251]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = (2, 3,)\n",
    "torch.rand(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3713dbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., -0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b800705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "acedcc24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "514f65a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3, 3],\n",
       "        [3, 3, 3]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full(shape, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "81d9b119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.5000, 2.0000])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1, 2.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "19179e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-10.,  -5.,   0.,   5.,  10.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(-10, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bc103864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2589,  2.1135,  3.5481,  5.9566, 10.0000])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.logspace(0.1, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "69fe3c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dcfd50",
   "metadata": {},
   "source": [
    "###  according to probability distribution\n",
    "* torch.normal(mean, std, out=None)\n",
    "* 正态分布: torch.randn(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "* 均匀分布: torch.rand(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "* 均匀分布: torch.randint(low=0, high, size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "* 随机排列: torch.randperm(n, out=None, dtype=torch.int64, layout=torch.strided, device=None, requires_grad=False)\n",
    "* 伯努利分布: torch.bernoulli(input, *, generator=None, out=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "21effb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2514,  0.3043,  3.3566,  3.5052,  4.0550,  5.6841,  7.0085,  7.8919,\n",
       "         9.1132, 10.0214])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(torch.arange(1., 11.), torch.arange(1, 0, -0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "734b939d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2239,  1.4996,  1.1819, -0.5354,  0.8123,  1.1935,  1.1532,  0.7853,\n",
       "         0.7847,  0.7890])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(torch.tensor(1.), torch.arange(1, 0, -0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0043ebbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9784, 3.1832, 2.9405, 4.5592, 5.2700, 5.6584, 7.1437, 7.6651, 9.0430,\n",
       "        9.4740])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(torch.arange(1., 11.), torch.tensor(0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4b217ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4.0019)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(torch.tensor(-1.), torch.tensor(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7fb46675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4589, -0.1495,  2.2695, -0.0911]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(0, 1, (1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "759e8a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9732, -1.1010, -0.7484],\n",
       "        [ 1.9863, -0.2902, -2.4220]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "88f427de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1049, 0.5137, 0.2674],\n",
       "        [0.4990, 0.7447, 0.7213]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bc46efe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9, 3],\n",
       "        [4, 6]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(3, 10, (2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e563d899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 4, 0, 1, 3, 2, 5, 6])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randperm(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "34d1b930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.empty(3, 3).uniform_(0, 1)\n",
    "torch.bernoulli(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e651b3f5",
   "metadata": {},
   "source": [
    "# 2.Attributes of a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3378c209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.Size([3])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3)\n",
    "print(tensor.dtype)\n",
    "print(tensor.shape)\n",
    "print(tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7056e82",
   "metadata": {},
   "source": [
    "# 3. tensor operation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2e67ba",
   "metadata": {},
   "source": [
    "### Standard numpy-like indexing and slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "08c2311f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([[0., 1., 0., 1.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [0., 1., 0., 1.]])\n",
      "tensor([[2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [0., 1., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "print(tensor)\n",
    "tensor[:, ::2] = 0\n",
    "print(tensor)\n",
    "tensor[:2, :] = 2\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c116196f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "print(tensor[-1, ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20affb17",
   "metadata": {},
   "source": [
    "### In-place operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "19f73ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [1., 2., 1., 2.],\n",
       "        [1., 2., 1., 2.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.add_(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e403ab",
   "metadata": {},
   "source": [
    "### Joining tensors \n",
    "* torch.cat(tensors, dim=0, out=None)\n",
    "* torch.stack(tensors, dim=0, out=None)\n",
    "* torch.chunk(input, chunks, dim=0)\n",
    "* torch.split(tensor, split_size_or_sections, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4672efd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9329, -0.9412],\n",
       "        [ 0.5536, -0.6499],\n",
       "        [-1.5436, -0.5975]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.randn(3, 2)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53f22e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9329, -0.9412],\n",
       "        [ 0.5536, -0.6499],\n",
       "        [-1.5436, -0.5975],\n",
       "        [ 0.9329, -0.9412],\n",
       "        [ 0.5536, -0.6499],\n",
       "        [-1.5436, -0.5975],\n",
       "        [ 0.9329, -0.9412],\n",
       "        [ 0.5536, -0.6499],\n",
       "        [-1.5436, -0.5975]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((tensor, tensor, tensor), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c75ae6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9329, -0.9412,  0.9329, -0.9412,  0.9329, -0.9412],\n",
       "        [ 0.5536, -0.6499,  0.5536, -0.6499,  0.5536, -0.6499],\n",
       "        [-1.5436, -0.5975, -1.5436, -0.5975, -1.5436, -0.5975]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((tensor, tensor, tensor), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf2cc373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9329, -0.9412],\n",
       "         [ 0.5536, -0.6499],\n",
       "         [-1.5436, -0.5975]],\n",
       "\n",
       "        [[ 0.9329, -0.9412],\n",
       "         [ 0.5536, -0.6499],\n",
       "         [-1.5436, -0.5975]],\n",
       "\n",
       "        [[ 0.9329, -0.9412],\n",
       "         [ 0.5536, -0.6499],\n",
       "         [-1.5436, -0.5975]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack((tensor, tensor, tensor), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c766d840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9329, -0.9412],\n",
       "         [ 0.9329, -0.9412],\n",
       "         [ 0.9329, -0.9412]],\n",
       "\n",
       "        [[ 0.5536, -0.6499],\n",
       "         [ 0.5536, -0.6499],\n",
       "         [ 0.5536, -0.6499]],\n",
       "\n",
       "        [[-1.5436, -0.5975],\n",
       "         [-1.5436, -0.5975],\n",
       "         [-1.5436, -0.5975]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack((tensor, tensor, tensor), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "416d1d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9329,  0.9329,  0.9329],\n",
       "         [-0.9412, -0.9412, -0.9412]],\n",
       "\n",
       "        [[ 0.5536,  0.5536,  0.5536],\n",
       "         [-0.6499, -0.6499, -0.6499]],\n",
       "\n",
       "        [[-1.5436, -1.5436, -1.5436],\n",
       "         [-0.5975, -0.5975, -0.5975]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack((tensor, tensor, tensor), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5ff962",
   "metadata": {},
   "source": [
    "### change shape\n",
    "* torch.reshape(input, shape)\n",
    "* torch.transpose(input, dim0, dim1)\n",
    "* torch.squeeze(input, dim=None, out=None)\n",
    "* torch.unsqueeze(input, dim, out=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8460fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.9329, -0.9412]]),\n",
       " tensor([[ 0.5536, -0.6499]]),\n",
       " tensor([[-1.5436, -0.5975]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.chunk(tensor, 3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34fe13ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.9329],\n",
       "         [ 0.5536],\n",
       "         [-1.5436]]),\n",
       " tensor([[-0.9412],\n",
       "         [-0.6499],\n",
       "         [-0.5975]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.chunk(tensor, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22310a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.9329, -0.9412]]),\n",
       " tensor([[ 0.5536, -0.6499]]),\n",
       " tensor([[-1.5436, -0.5975]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.split(tensor, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a84c4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.9329],\n",
       "         [ 0.5536],\n",
       "         [-1.5436]]),\n",
       " tensor([[-0.9412],\n",
       "         [-0.6499],\n",
       "         [-0.5975]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.split(tensor, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e7ed240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9329, -0.9412,  0.5536],\n",
       "        [-0.6499, -1.5436, -0.5975]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.reshape(tensor, (2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "830fc627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9329,  0.5536, -1.5436],\n",
       "        [-0.9412, -0.6499, -0.5975]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(tensor, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5eda6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.zeros(2, 3, 1)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e61f4732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.squeeze(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3d14780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       "\n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.]]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(tensor, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2830becc",
   "metadata": {},
   "source": [
    "### index\n",
    "* torch.index_select(input, dim, index, out=None)\n",
    "* torch.masked_select(input, mask, out=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33c46311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.1382,  0.3900, -0.9062,  0.8873],\n",
       "        [-0.7923, -1.5249, -0.1997, -0.0821],\n",
       "        [-1.0587,  0.3344, -0.7804,  0.0804]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.randn((3, 4))\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e69eff4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.1382,  0.3900, -0.9062,  0.8873],\n",
       "        [-1.0587,  0.3344, -0.7804,  0.0804]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = torch.tensor([0, 2])\n",
    "torch.index_select(tensor, 0, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "548f5185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False,  True],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = tensor.ge(0.5)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef38a1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.1382, 0.8873])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.masked_select(tensor, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0750763",
   "metadata": {},
   "source": [
    "### move to gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79d07ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(tensor.device)\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to(\"cuda\")\n",
    "print(tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2b702e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
