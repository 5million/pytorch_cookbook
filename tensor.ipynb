{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4edb58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fbb99496090>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "torch.manual_seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524cdbeb",
   "metadata": {},
   "source": [
    "# 1.create a tensor\n",
    "### directly from data\n",
    " * torch.tensor(data, dtype=None, device=None, requires_grad=False, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21c52a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1000,  2.0000],\n",
       "        [-2.0000,  3.0000],\n",
       "        [ 0.5000,  0.2000]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[0.1, 2], [-2, 3], [0.5, 0.2]]\n",
    "torch.tensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e125fb",
   "metadata": {},
   "source": [
    "### from numpy\n",
    " * torch.from_numpy(ndarray, dtype=None, device=None, requires_grad=False, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5d55ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1000,  2.0000],\n",
       "        [-2.0000,  3.0000],\n",
       "        [ 0.5000,  0.2000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "torch.from_numpy(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1154138d",
   "metadata": {},
   "source": [
    "### from another tensor\n",
    "The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden.\n",
    " * torch.ones_like(input, dtype=None, layout=None, device=None, requires_grad=False)\n",
    " * torch.zeros_like(input, dtype=None, layout=None, device=None, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8451d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.from_numpy(data)\n",
    "torch.ones_like(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7458bee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e1a40717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.1416, 3.1416],\n",
       "        [3.1416, 3.1416],\n",
       "        [3.1416, 3.1416]], dtype=torch.float64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full_like(tensor, 3.14159)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b6a3fb",
   "metadata": {},
   "source": [
    "### with random or constant values\n",
    "shape is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of the output tensor\n",
    "* torch.empty(shape)\n",
    "* torch.ones(*size, out=None, dtype=None, layout=torch.strided, device=None, required_grad=False)\n",
    "* torch.zeros(*size, out=None, dtype=None, layout=torch.strided, device=None, required_grad=False)\n",
    "* torch.full(size, fill_value, out=None, dtype=None, layout=torch.strided, device=None, required_grad=False)\n",
    "* torch.arange(start=0, end, step=1, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "* torch.linspace(start, end, steps=100, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "* torch.logspace(start, end, steps=100, base=10.0, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "* torch.eye(n, m=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8842f3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5349, 0.1988, 0.6592],\n",
       "        [0.6569, 0.2328, 0.4251]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = (2, 3,)\n",
    "torch.rand(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3713dbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., -0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b800705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "acedcc24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "514f65a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3, 3],\n",
       "        [3, 3, 3]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full(shape, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "81d9b119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.5000, 2.0000])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1, 2.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "19179e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-10.,  -5.,   0.,   5.,  10.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(-10, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bc103864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2589,  2.1135,  3.5481,  5.9566, 10.0000])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.logspace(0.1, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "69fe3c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dcfd50",
   "metadata": {},
   "source": [
    "###  according to probability distribution\n",
    "* torch.normal(mean, std, out=None)\n",
    "* 正态分布: torch.randn(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "* 均匀分布: torch.rand(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "* 均匀分布: torch.randint(low=0, high, size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "* 随机排列: torch.randperm(n, out=None, dtype=torch.int64, layout=torch.strided, device=None, requires_grad=False)\n",
    "* 伯努利分布: torch.bernoulli(input, *, generator=None, out=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "21effb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2514,  0.3043,  3.3566,  3.5052,  4.0550,  5.6841,  7.0085,  7.8919,\n",
       "         9.1132, 10.0214])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(torch.arange(1., 11.), torch.arange(1, 0, -0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "734b939d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2239,  1.4996,  1.1819, -0.5354,  0.8123,  1.1935,  1.1532,  0.7853,\n",
       "         0.7847,  0.7890])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(torch.tensor(1.), torch.arange(1, 0, -0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0043ebbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9784, 3.1832, 2.9405, 4.5592, 5.2700, 5.6584, 7.1437, 7.6651, 9.0430,\n",
       "        9.4740])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(torch.arange(1., 11.), torch.tensor(0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4b217ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4.0019)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(torch.tensor(-1.), torch.tensor(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7fb46675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4589, -0.1495,  2.2695, -0.0911]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(0, 1, (1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "759e8a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9732, -1.1010, -0.7484],\n",
       "        [ 1.9863, -0.2902, -2.4220]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "88f427de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1049, 0.5137, 0.2674],\n",
       "        [0.4990, 0.7447, 0.7213]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bc46efe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9, 3],\n",
       "        [4, 6]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(3, 10, (2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e563d899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 4, 0, 1, 3, 2, 5, 6])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randperm(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "34d1b930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.empty(3, 3).uniform_(0, 1)\n",
    "torch.bernoulli(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7056e82",
   "metadata": {},
   "source": [
    "# 2. tensor operation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e403ab",
   "metadata": {},
   "source": [
    "* torch.cat(tensors, dim=0, out=None)\n",
    "* torch.stack(tensors, dim=0, out=None)\n",
    "* torch.chunk(input, chunks, dim=0)\n",
    "* torch.split(tensor, split_size_or_sections, dim=0)\n",
    "* torch.reshape(input, shape)\n",
    "* torch.transpose(input, dim0, dim1)\n",
    "* torch.squeeze(input, dim=None, out=None)\n",
    "* torch.unsqueeze(input, dim, out=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4672efd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3603,  0.6343],\n",
       "        [-0.6197,  0.5740],\n",
       "        [-0.0798,  0.9674]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3, 2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "53f22e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8150, -0.9118],\n",
       "        [-0.0739,  1.1056],\n",
       "        [-0.8667, -0.1373],\n",
       "        [-0.8150, -0.9118],\n",
       "        [-0.0739,  1.1056],\n",
       "        [-0.8667, -0.1373],\n",
       "        [-0.8150, -0.9118],\n",
       "        [-0.0739,  1.1056],\n",
       "        [-0.8667, -0.1373]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((a, a, a), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c75ae6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8150, -0.9118, -0.8150, -0.9118, -0.8150, -0.9118],\n",
       "        [-0.0739,  1.1056, -0.0739,  1.1056, -0.0739,  1.1056],\n",
       "        [-0.8667, -0.1373, -0.8667, -0.1373, -0.8667, -0.1373]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((a, a, a), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cf2cc373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8150, -0.9118],\n",
       "         [-0.0739,  1.1056],\n",
       "         [-0.8667, -0.1373]],\n",
       "\n",
       "        [[-0.8150, -0.9118],\n",
       "         [-0.0739,  1.1056],\n",
       "         [-0.8667, -0.1373]],\n",
       "\n",
       "        [[-0.8150, -0.9118],\n",
       "         [-0.0739,  1.1056],\n",
       "         [-0.8667, -0.1373]]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack((a, a, a), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c766d840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8150, -0.9118],\n",
       "         [-0.8150, -0.9118],\n",
       "         [-0.8150, -0.9118]],\n",
       "\n",
       "        [[-0.0739,  1.1056],\n",
       "         [-0.0739,  1.1056],\n",
       "         [-0.0739,  1.1056]],\n",
       "\n",
       "        [[-0.8667, -0.1373],\n",
       "         [-0.8667, -0.1373],\n",
       "         [-0.8667, -0.1373]]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack((a, a, a), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "416d1d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8150, -0.8150, -0.8150],\n",
       "         [-0.9118, -0.9118, -0.9118]],\n",
       "\n",
       "        [[-0.0739, -0.0739, -0.0739],\n",
       "         [ 1.1056,  1.1056,  1.1056]],\n",
       "\n",
       "        [[-0.8667, -0.8667, -0.8667],\n",
       "         [-0.1373, -0.1373, -0.1373]]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack((a, a, a), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a8460fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.8150, -0.9118]]),\n",
       " tensor([[-0.0739,  1.1056]]),\n",
       " tensor([[-0.8667, -0.1373]]))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.chunk(a, 3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "34fe13ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.8150],\n",
       "         [-0.0739],\n",
       "         [-0.8667]]),\n",
       " tensor([[-0.9118],\n",
       "         [ 1.1056],\n",
       "         [-0.1373]]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.chunk(a, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "22310a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.8150, -0.9118]]),\n",
       " tensor([[-0.0739,  1.1056]]),\n",
       " tensor([[-0.8667, -0.1373]]))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.split(a, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1a84c4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.8150],\n",
       "         [-0.0739],\n",
       "         [-0.8667]]),\n",
       " tensor([[-0.9118],\n",
       "         [ 1.1056],\n",
       "         [-0.1373]]))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.split(a, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3e7ed240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3603,  0.6343, -0.6197],\n",
       "        [ 0.5740, -0.0798,  0.9674]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.reshape(a, (2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "830fc627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3603, -0.6197, -0.0798],\n",
       "        [ 0.6343,  0.5740,  0.9674]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(a, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a5eda6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.]]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(2, 3, 1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e61f4732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.squeeze(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b3d14780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       "\n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [0.]]]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(x, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2830becc",
   "metadata": {},
   "source": [
    "### index\n",
    "* torch.index_select(input, dim, index, out=None)\n",
    "* torch.masked_select(input, mask, out=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "33c46311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5644,  1.1560, -0.6877,  0.3515],\n",
       "        [ 1.5050, -0.5220,  0.0232, -3.3208],\n",
       "        [ 1.9626,  0.1007, -1.2005,  1.2650]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn((3, 4))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e69eff4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5644,  1.1560, -0.6877,  0.3515],\n",
       "        [ 1.9626,  0.1007, -1.2005,  1.2650]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = torch.tensor([0, 2])\n",
    "torch.index_select(a, 0, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "548f5185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False, False],\n",
       "        [ True, False, False, False],\n",
       "        [ True, False, False,  True]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = a.ge(0.5)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ef38a1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1560, 1.5050, 1.9626, 1.2650])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.masked_select(a, mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
